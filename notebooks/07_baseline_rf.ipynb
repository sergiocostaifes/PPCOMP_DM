{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMfRc0zKqVuZaHVAJ1kVMl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergiocostaifes/PPCOMP_DM/blob/main/notebooks/07_baseline_rf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 07_baseline_rf.ipynb — Baseline Supervisionado (Random Forest)\n",
        "\n",
        "Objetivo  \n",
        "Treinar e avaliar um baseline supervisionado com **Random Forest** sobre a base rotulada em janelas de 5 minutos (Notebook 06), comparando:\n",
        "\n",
        "1. **Classificação binária**: `is_event = 1` para {BEFORE, DURING, AFTER} vs `NORMAL`\n",
        "2. **Classificação multiclasse**: {NORMAL, BEFORE, DURING, AFTER}\n",
        "\n",
        "A avaliação é feita com **split temporal** para evitar vazamento de informação futura.\n",
        "\n",
        "Entradas (artefatos do pipeline)\n",
        "\n",
        "- `window_5min_labeled.parquet` (Notebook 06)\n",
        "\n",
        "Saídas (artefatos deste Notebook)\n",
        "\n",
        "- `rf_binary.joblib`\n",
        "- `rf_multiclass.joblib`\n",
        "- `07_baseline_rf_summary.json`\n",
        "\n",
        "Split temporal\n",
        "\n",
        "Este notebook suporta duas estratégias:\n",
        "\n",
        "- **Corte fixo** (default): treino = 80% inicial; teste = 20% final\n",
        "- **TimeSeriesSplit** (opcional): validação em múltiplos folds temporais\n",
        "\n",
        "Métricas reportadas\n",
        "\n",
        "- Binário: accuracy, precision, recall, f1, ROC-AUC (quando aplicável)\n",
        "- Multiclasse: accuracy, macro-f1, weighted-f1, classification report\n",
        "- Matriz de confusão (binário e multiclasse)\n",
        "\n",
        "Features\n",
        "\n",
        "- Exclui colunas não-numéricas e colunas de rótulo (`state`, `is_critical`)\n",
        "- Preserva `bucket_id` apenas como referência (não como feature)\n",
        "\n",
        "Observações\n",
        "\n",
        "- O dataset é desbalanceado, especialmente na classe DURING.\n",
        "- Random Forest é utilizado como baseline interpretável e robusto.\n",
        "- Ajustes como class_weight podem ser aplicados em iterações futuras."
      ],
      "metadata": {
        "id": "XuqeShvctl3t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "U55VPQBZtMwQ",
        "outputId": "b2f6ff6d-b581-406a-a992-b176d5e9d79b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[Bootstrap] Atualizando repositório (git pull).\n",
            "[Bootstrap] CWD = /content/drive/MyDrive/Mestrado/PPCOMP_DM\n",
            "FEATURES_PATH = /content/drive/MyDrive/Mestrado/02-datasets/03-features\n",
            "REPORTS_PATH  = /content/drive/MyDrive/Mestrado/04-reports\n",
            "MODELS_PATH   = /content/drive/MyDrive/Mestrado/03-models\n",
            "[07_baseline_rf] Dataset rotulado: shape=(8914, 27)\n",
            "[07_baseline_rf] Features usadas: 24\n",
            "[07_baseline_rf] Classes (multiclasse): ['AFTER', 'BEFORE', 'DURING', 'NORMAL']\n",
            "[07_baseline_rf] Split temporal: train=7131 test=1783 (modo=fixed)\n",
            "[07_baseline_rf] [BIN] acc=0.8643 prec=0.9575 rec=0.5177 f1=0.6721 auc=0.8787599100887585\n",
            "[07_baseline_rf] [MULTI] acc=0.8284 macro_f1=0.6554 weighted_f1=0.7730\n",
            "[07_baseline_rf] Notebook 07 finalizado com sucesso.\n",
            "\n",
            "=== MULTICLASS REPORT ===\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      NORMAL       0.85      0.99      0.91      1304\n",
            "      BEFORE       0.27      0.02      0.03       242\n",
            "      DURING       1.00      1.00      1.00        61\n",
            "       AFTER       0.66      0.70      0.68       176\n",
            "\n",
            "    accuracy                           0.83      1783\n",
            "   macro avg       0.69      0.68      0.66      1783\n",
            "weighted avg       0.76      0.83      0.77      1783\n",
            "\n",
            "\n",
            "=== CONFUSION MATRIX (BIN) ===\n",
            " [[1293, 11], [231, 248]]\n",
            "\n",
            "=== CONFUSION MATRIX (MULTI) labels= ['NORMAL', 'BEFORE', 'DURING', 'AFTER'] ===\n",
            " [[1289, 7, 0, 8], [182, 4, 0, 56], [0, 0, 61, 0], [49, 4, 0, 123]]\n",
            "\n",
            "Models saved:\n",
            " /content/drive/MyDrive/Mestrado/03-models/rf_binary.joblib \n",
            " /content/drive/MyDrive/Mestrado/03-models/rf_multiclass.joblib\n",
            "\n",
            "Summary saved:\n",
            " /content/drive/MyDrive/Mestrado/04-reports/07_baseline_rf_summary.json\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 07_baseline_rf.ipynb\n",
        "# Baseline supervisionado com Random Forest (binário vs multiclasse)\n",
        "# Split temporal + métricas + matriz de confusão + salvamento do modelo\n",
        "# ============================================================\n",
        "\n",
        "# -----------------------------\n",
        "# 0) BOOTSTRAP (Colab + Repo)\n",
        "# -----------------------------\n",
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import importlib\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Colab Drive\n",
        "if not Path(\"/content/drive/MyDrive\").exists():\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "else:\n",
        "    print(\"[Bootstrap] Google Drive já montado.\")\n",
        "\n",
        "REPO_DIR = Path(\"/content/drive/MyDrive/Mestrado/PPCOMP_DM\")\n",
        "GITHUB_REPO = \"https://github.com/sergiocostaifes/PPCOMP_DM.git\"\n",
        "\n",
        "if not REPO_DIR.exists():\n",
        "    REPO_DIR.parent.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"[Bootstrap] Clonando repositório em: {REPO_DIR}\")\n",
        "    subprocess.run([\"git\", \"clone\", GITHUB_REPO, str(REPO_DIR)], check=True)\n",
        "else:\n",
        "    try:\n",
        "        print(\"[Bootstrap] Atualizando repositório (git pull).\")\n",
        "        subprocess.run([\"git\", \"-C\", str(REPO_DIR), \"pull\"], check=True)\n",
        "    except Exception as e:\n",
        "        print(\"[Bootstrap] Aviso: não foi possível atualizar via git pull:\", e)\n",
        "\n",
        "os.chdir(str(REPO_DIR))\n",
        "print(\"[Bootstrap] CWD =\", os.getcwd())\n",
        "\n",
        "repo_str = str(REPO_DIR)\n",
        "if repo_str not in sys.path:\n",
        "    sys.path.insert(0, repo_str)\n",
        "\n",
        "importlib.invalidate_caches()\n",
        "\n",
        "from src.paths import FEATURES_PATH, REPORTS_PATH, MODELS_PATH, ensure_dirs\n",
        "ensure_dirs()\n",
        "\n",
        "print(\"FEATURES_PATH =\", FEATURES_PATH)\n",
        "print(\"REPORTS_PATH  =\", REPORTS_PATH)\n",
        "print(\"MODELS_PATH   =\", MODELS_PATH)\n",
        "\n",
        "def log(msg: str) -> None:\n",
        "    print(f\"[07_baseline_rf] {msg}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 1) Imports ML\n",
        "# -----------------------------\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_recall_fscore_support,\n",
        "    classification_report, confusion_matrix,\n",
        "    roc_auc_score\n",
        ")\n",
        "import joblib\n",
        "\n",
        "# -----------------------------\n",
        "# 2) Carregar dataset rotulado\n",
        "# -----------------------------\n",
        "DATA_FILE = FEATURES_PATH / \"window_5min_labeled.parquet\"\n",
        "assert DATA_FILE.exists(), f\"Arquivo não encontrado: {DATA_FILE}\"\n",
        "\n",
        "df = pd.read_parquet(DATA_FILE).sort_values(\"bucket_id\").reset_index(drop=True)\n",
        "log(f\"Dataset rotulado: shape={df.shape}\")\n",
        "\n",
        "assert \"state\" in df.columns, \"Coluna 'state' ausente.\"\n",
        "assert \"bucket_id\" in df.columns, \"Coluna 'bucket_id' ausente.\"\n",
        "\n",
        "# -----------------------------\n",
        "# 3) Preparar features (X)\n",
        "# -----------------------------\n",
        "# Remover colunas de label / não numéricas\n",
        "drop_cols = {\"state\"}  # alvo\n",
        "# is_critical veio do NB05; pode existir e é derivado do NB04 — remover para não vazar definição\n",
        "if \"is_critical\" in df.columns:\n",
        "    drop_cols.add(\"is_critical\")\n",
        "\n",
        "# bucket_id: manter apenas para referência temporal, não como feature\n",
        "drop_cols.add(\"bucket_id\")\n",
        "\n",
        "# Selecionar colunas numéricas\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "X_cols = [c for c in numeric_cols if c not in drop_cols]\n",
        "\n",
        "if len(X_cols) == 0:\n",
        "    raise ValueError(\"Nenhuma feature numérica encontrada após filtragem.\")\n",
        "\n",
        "X = df[X_cols].copy()\n",
        "y_multi = df[\"state\"].astype(str).copy()\n",
        "\n",
        "log(f\"Features usadas: {len(X_cols)}\")\n",
        "log(f\"Classes (multiclasse): {sorted(y_multi.unique().tolist())}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 4) Split temporal (corte fixo default)\n",
        "# -----------------------------\n",
        "SPLIT_MODE = \"fixed\"  # \"fixed\" ou \"tscv\"\n",
        "TEST_RATIO = 0.20\n",
        "\n",
        "n = len(df)\n",
        "test_size = int(np.ceil(n * TEST_RATIO))\n",
        "train_end = n - test_size\n",
        "\n",
        "X_train, X_test = X.iloc[:train_end], X.iloc[train_end:]\n",
        "y_train_multi, y_test_multi = y_multi.iloc[:train_end], y_multi.iloc[train_end:]\n",
        "\n",
        "log(f\"Split temporal: train={len(X_train)} test={len(X_test)} (modo={SPLIT_MODE})\")\n",
        "\n",
        "# -----------------------------\n",
        "# 5) Cenário binário: evento vs normal\n",
        "# -----------------------------\n",
        "y_train_bin = (y_train_multi != \"NORMAL\").astype(int)\n",
        "y_test_bin  = (y_test_multi  != \"NORMAL\").astype(int)\n",
        "\n",
        "rf_bin = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    random_state=SEED,\n",
        "    n_jobs=-1,\n",
        "    class_weight=\"balanced_subsample\"\n",
        ")\n",
        "\n",
        "rf_bin.fit(X_train, y_train_bin)\n",
        "pred_bin = rf_bin.predict(X_test)\n",
        "proba_bin = rf_bin.predict_proba(X_test)[:, 1] if hasattr(rf_bin, \"predict_proba\") else None\n",
        "\n",
        "acc_bin = accuracy_score(y_test_bin, pred_bin)\n",
        "prec_bin, rec_bin, f1_bin, _ = precision_recall_fscore_support(\n",
        "    y_test_bin, pred_bin, average=\"binary\", zero_division=0\n",
        ")\n",
        "\n",
        "auc_bin = None\n",
        "if proba_bin is not None and len(np.unique(y_test_bin)) == 2:\n",
        "    try:\n",
        "        auc_bin = float(roc_auc_score(y_test_bin, proba_bin))\n",
        "    except Exception:\n",
        "        auc_bin = None\n",
        "\n",
        "cm_bin = confusion_matrix(y_test_bin, pred_bin).tolist()\n",
        "\n",
        "log(f\"[BIN] acc={acc_bin:.4f} prec={prec_bin:.4f} rec={rec_bin:.4f} f1={f1_bin:.4f} auc={auc_bin}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 6) Cenário multiclasse: NORMAL/BEFORE/DURING/AFTER\n",
        "# -----------------------------\n",
        "rf_multi = RandomForestClassifier(\n",
        "    n_estimators=400,\n",
        "    random_state=SEED,\n",
        "    n_jobs=-1,\n",
        "    class_weight=\"balanced_subsample\"\n",
        ")\n",
        "\n",
        "rf_multi.fit(X_train, y_train_multi)\n",
        "pred_multi = rf_multi.predict(X_test)\n",
        "\n",
        "acc_multi = accuracy_score(y_test_multi, pred_multi)\n",
        "prec_m, rec_m, f1_m, _ = precision_recall_fscore_support(\n",
        "    y_test_multi, pred_multi, average=\"macro\", zero_division=0\n",
        ")\n",
        "prec_w, rec_w, f1_w, _ = precision_recall_fscore_support(\n",
        "    y_test_multi, pred_multi, average=\"weighted\", zero_division=0\n",
        ")\n",
        "\n",
        "labels = [\"NORMAL\", \"BEFORE\", \"DURING\", \"AFTER\"]\n",
        "cm_multi = confusion_matrix(y_test_multi, pred_multi, labels=labels).tolist()\n",
        "report_multi = classification_report(y_test_multi, pred_multi, labels=labels, zero_division=0)\n",
        "\n",
        "log(f\"[MULTI] acc={acc_multi:.4f} macro_f1={f1_m:.4f} weighted_f1={f1_w:.4f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 7) (Opcional) TimeSeriesSplit rápido (apenas multiclasse)\n",
        "# -----------------------------\n",
        "tscv_results = []\n",
        "if SPLIT_MODE == \"tscv\":\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    for fold, (tr, te) in enumerate(tscv.split(X), start=1):\n",
        "        X_tr, X_te = X.iloc[tr], X.iloc[te]\n",
        "        y_tr, y_te = y_multi.iloc[tr], y_multi.iloc[te]\n",
        "        clf = RandomForestClassifier(\n",
        "            n_estimators=300,\n",
        "            random_state=SEED,\n",
        "            n_jobs=-1,\n",
        "            class_weight=\"balanced_subsample\"\n",
        "        )\n",
        "        clf.fit(X_tr, y_tr)\n",
        "        y_hat = clf.predict(X_te)\n",
        "        f1_macro = precision_recall_fscore_support(\n",
        "            y_te, y_hat, average=\"macro\", zero_division=0\n",
        "        )[2]\n",
        "        tscv_results.append({\"fold\": fold, \"f1_macro\": float(f1_macro)})\n",
        "\n",
        "# -----------------------------\n",
        "# 8) Salvar modelos\n",
        "# -----------------------------\n",
        "bin_model_path = MODELS_PATH / \"rf_binary.joblib\"\n",
        "multi_model_path = MODELS_PATH / \"rf_multiclass.joblib\"\n",
        "\n",
        "joblib.dump(rf_bin, bin_model_path)\n",
        "joblib.dump(rf_multi, multi_model_path)\n",
        "\n",
        "# -----------------------------\n",
        "# 9) Summary (JSON) + prints úteis\n",
        "# -----------------------------\n",
        "summary = {\n",
        "    \"seed\": SEED,\n",
        "    \"split_mode\": SPLIT_MODE,\n",
        "    \"test_ratio\": TEST_RATIO,\n",
        "    \"rows_total\": int(n),\n",
        "    \"rows_train\": int(len(X_train)),\n",
        "    \"rows_test\": int(len(X_test)),\n",
        "    \"n_features\": int(len(X_cols)),\n",
        "    \"features\": X_cols,\n",
        "    \"class_distribution_total\": df[\"state\"].value_counts().to_dict(),\n",
        "    \"binary\": {\n",
        "        \"acc\": float(acc_bin),\n",
        "        \"precision\": float(prec_bin),\n",
        "        \"recall\": float(rec_bin),\n",
        "        \"f1\": float(f1_bin),\n",
        "        \"roc_auc\": auc_bin,\n",
        "        \"confusion_matrix\": cm_bin\n",
        "    },\n",
        "    \"multiclass\": {\n",
        "        \"acc\": float(acc_multi),\n",
        "        \"macro_f1\": float(f1_m),\n",
        "        \"weighted_f1\": float(f1_w),\n",
        "        \"confusion_matrix\": cm_multi,\n",
        "        \"labels_order\": labels,\n",
        "        \"classification_report_text\": report_multi\n",
        "    },\n",
        "    \"tscv_multiclass\": tscv_results,\n",
        "    \"models\": {\n",
        "        \"binary_path\": str(bin_model_path),\n",
        "        \"multiclass_path\": str(multi_model_path)\n",
        "    }\n",
        "}\n",
        "\n",
        "summary_file = REPORTS_PATH / \"07_baseline_rf_summary.json\"\n",
        "summary_file.write_text(json.dumps(summary, indent=2, ensure_ascii=False))\n",
        "\n",
        "log(\"Notebook 07 finalizado com sucesso.\")\n",
        "print(\"\\n=== MULTICLASS REPORT ===\\n\")\n",
        "print(report_multi)\n",
        "print(\"\\n=== CONFUSION MATRIX (BIN) ===\\n\", cm_bin)\n",
        "print(\"\\n=== CONFUSION MATRIX (MULTI) labels=\", labels, \"===\\n\", cm_multi)\n",
        "print(\"\\nModels saved:\\n\", bin_model_path, \"\\n\", multi_model_path)\n",
        "print(\"\\nSummary saved:\\n\", summary_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Achados do Notebook 07 — Baseline Supervisionado (Random Forest)\n",
        "\n",
        "### Estrutura experimental\n",
        "\n",
        "- Total de janelas: 8914\n",
        "- Split temporal (80/20) preservando ordem cronológica\n",
        "- 24 features numéricas utilizadas\n",
        "- Dois cenários avaliados:\n",
        "  - Classificação binária (evento vs normal)\n",
        "  - Classificação multiclasse (NORMAL / BEFORE / DURING / AFTER)\n",
        "\n",
        "Não houve vazamento temporal.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Resultados — Classificação Binária\n",
        "\n",
        "Métricas:\n",
        "\n",
        "- Accuracy: 0.864\n",
        "- Precision: 0.958\n",
        "- Recall: 0.518\n",
        "- F1-score: 0.672\n",
        "- ROC-AUC: 0.879\n",
        "\n",
        "Interpretação:\n",
        "\n",
        "O modelo apresenta alta precisão e AUC robusta, indicando boa capacidade de separação entre janelas normais e janelas associadas a eventos.\n",
        "\n",
        "O recall moderado sugere comportamento conservador, reduzindo falsos alarmes, característica desejável em ambientes críticos.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Resultados — Classificação Multiclasse\n",
        "\n",
        "Métricas globais:\n",
        "\n",
        "- Accuracy: 0.828\n",
        "- Macro-F1: 0.655\n",
        "- Weighted-F1: 0.773\n",
        "\n",
        "Desempenho por classe:\n",
        "\n",
        "- NORMAL: F1 ≈ 0.91\n",
        "- BEFORE: F1 ≈ 0.03\n",
        "- DURING: F1 = 1.00\n",
        "- AFTER: F1 ≈ 0.68\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Principais Achados\n",
        "\n",
        "### 3.1 Excelente separação da classe DURING\n",
        "\n",
        "A classe DURING foi identificada com precisão e recall perfeitos.\n",
        "\n",
        "Isso indica que:\n",
        "\n",
        "- As features estatísticas capturam fortemente a assinatura de degradação.\n",
        "- A definição formal de episódios (Notebook 04) é consistente.\n",
        "- A engenharia de atributos (Notebook 05) é adequada para detectar regimes críticos.\n",
        "\n",
        "Este é um resultado estrutural importante para a dissertação.\n",
        "\n",
        "---\n",
        "\n",
        "### 3.2 Dificuldade em detectar BEFORE\n",
        "\n",
        "A classe BEFORE apresentou recall extremamente baixo.\n",
        "\n",
        "Isso sugere que:\n",
        "\n",
        "- A transição pré-evento não apresenta separação estatística clara.\n",
        "- Pode ser necessária modelagem sequencial.\n",
        "- Pode ser interessante revisar a definição de janela BEFORE.\n",
        "- Pode haver necessidade de features acumuladas ou temporais mais longas.\n",
        "\n",
        "Esse comportamento é coerente com a natureza gradual de mudanças de regime.\n",
        "\n",
        "---\n",
        "\n",
        "### 3.3 AFTER apresenta regime intermediário\n",
        "\n",
        "A classe AFTER mantém assinatura detectável, com F1 moderado.\n",
        "\n",
        "Isso indica que:\n",
        "\n",
        "- A estabilização pós-evento preserva traços estatísticos distintos.\n",
        "- O modelo consegue distinguir recuperação parcial de normalidade plena.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Implicações Científicas\n",
        "\n",
        "1. A segmentação temporal baseada em μ + 2σ mostrou-se operacionalmente válida.\n",
        "2. Eventos críticos são estatisticamente separáveis.\n",
        "3. A fase pré-evento requer modelagem temporal mais sofisticada.\n",
        "4. O baseline Random Forest estabelece referência comparativa para modelos futuros.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Conclusão\n",
        "\n",
        "O Notebook 07 confirma que a estrutura de dados construída ao longo dos Notebooks 01–06 é consistente e cientificamente utilizável.\n",
        "\n",
        "A partir deste ponto, a pesquisa pode evoluir para:\n",
        "\n",
        "- Modelos temporais mais avançados\n",
        "- Ajuste de hiperparâmetros\n",
        "- Técnicas de balanceamento\n",
        "- Avaliação preditiva antecipada (forecasting de episódios)"
      ],
      "metadata": {
        "id": "4HxmQHHlu4rE"
      }
    }
  ]
}