{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiWtC0WlH2vCJc3jkSf07p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergiocostaifes/PPCOMP_DM/blob/main/notebooks/03_windowing_episodes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfHgBlozWnUQ"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 03_windowing_episodes.ipynb\n",
        "# Série por hora + detecção de episódios (baseline μ+2σ)\n",
        "# =========================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "CLEAN_PARQUET = PROCESSED_PATH / \"google_trace_clean.parquet\"\n",
        "assert CLEAN_PARQUET.exists(), f\"Não achei: {CLEAN_PARQUET}\"\n",
        "\n",
        "df = pd.read_parquet(CLEAN_PARQUET)\n",
        "log(f\"Dataset limpo carregado: {df.shape}\")\n",
        "\n",
        "# 1) Série f(h): falhas por hora, incluindo horas com zero falhas\n",
        "hmin = int(df[\"hour\"].min())\n",
        "hmax = int(df[\"hour\"].max())\n",
        "\n",
        "fail_by_hour_full = (\n",
        "    df[df[\"failed\"] == 1]\n",
        "    .groupby(\"hour\")\n",
        "    .size()\n",
        "    .reindex(range(hmin, hmax + 1), fill_value=0)\n",
        ")\n",
        "\n",
        "series = fail_by_hour_full  # hour 0 já foi removida no notebook anterior\n",
        "\n",
        "log(f\"Intervalo horas: {hmin}..{hmax}\")\n",
        "log(f\"Total horas na série: {len(series)}\")\n",
        "log(f\"Total falhas: {int(series.sum())}\")\n",
        "log(f\"Pico máximo: {int(series.max())}\")\n",
        "\n",
        "# 2) Threshold estatístico T = μ + 2σ\n",
        "mu = float(series.mean())\n",
        "sigma = float(series.std())\n",
        "threshold = mu + 2*sigma\n",
        "\n",
        "log(f\"μ (média): {mu:.2f}\")\n",
        "log(f\"σ (desvio padrão): {sigma:.2f}\")\n",
        "log(f\"T = μ + 2σ: {threshold:.2f}\")\n",
        "\n",
        "# 3) Detectar episódios como intervalos contínuos acima do threshold\n",
        "episodes = []\n",
        "start = None\n",
        "\n",
        "for h, val in series.items():\n",
        "    if val > threshold:\n",
        "        if start is None:\n",
        "            start = int(h)\n",
        "    else:\n",
        "        if start is not None:\n",
        "            episodes.append((start, int(h) - 1))\n",
        "            start = None\n",
        "\n",
        "if start is not None:\n",
        "    episodes.append((start, int(series.index.max())))\n",
        "\n",
        "log(f\"Número de episódios detectados: {len(episodes)}\")\n",
        "log(f\"Primeiros episódios: {episodes[:10]}\")\n",
        "\n",
        "# 4) Tabela de episódios (métricas)\n",
        "rows = []\n",
        "for (hs, he) in episodes:\n",
        "    seg = series.loc[hs:he]\n",
        "    rows.append({\n",
        "        \"episode_id\": len(rows) + 1,\n",
        "        \"start_hour\": hs,\n",
        "        \"end_hour\": he,\n",
        "        \"duration_hours\": int(he - hs + 1),\n",
        "        \"max_failures_in_hour\": int(seg.max()),\n",
        "        \"mean_failures_in_episode\": float(seg.mean()),\n",
        "        \"total_failures_in_episode\": int(seg.sum()),\n",
        "        \"threshold\": float(threshold),\n",
        "        \"mu\": float(mu),\n",
        "        \"sigma\": float(sigma),\n",
        "    })\n",
        "\n",
        "episodes_df = pd.DataFrame(rows)\n",
        "\n",
        "# 5) Salvar artefatos\n",
        "WINDOW_BASE = FEATURES_PATH / \"failures_by_hour.parquet\"\n",
        "EPISODES_OUT = FEATURES_PATH / \"episodes_detected.parquet\"\n",
        "\n",
        "series.reset_index().rename(columns={\"index\": \"hour\", 0: \"failures\"}).to_parquet(WINDOW_BASE, index=False, compression=\"snappy\")\n",
        "episodes_df.to_parquet(EPISODES_OUT, index=False, compression=\"snappy\")\n",
        "\n",
        "log(f\"Salvo: {WINDOW_BASE}\")\n",
        "log(f\"Salvo: {EPISODES_OUT}\")\n",
        "\n",
        "episodes_df.sort_values(\"max_failures_in_hour\", ascending=False).head(10)"
      ]
    }
  ]
}